{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Library"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import platform\n","import os\n","import random\n","import scipy\n","\n","import pandas as pd\n","from sklearn.metrics import f1_score, classification_report\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","import numpy as np\n","import sklearn\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["SEED = 42\n","\n","os.environ['PYTHONHASHSEED']=str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)\n",""]},{"cell_type":"code","execution_count":3,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Python version: 3.8.3\nTensorflow Version: 2.2.0\nTensorflow Addons Version: 0.10.0\nPandas Version: 1.0.3\nNumpy Version: 1.18.5\n"}],"source":["print('Python version:', platform.python_version())\n","print('Tensorflow Version:', tf.__version__)\n","print('Tensorflow Addons Version:', tfa.__version__)\n","print('Pandas Version:', pd.__version__)\n","print('Numpy Version:', np.__version__)\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def to_list(words):\n","    if words == '[]':\n","        return []\n","    else:\n","        words = words.strip('\"')\n","        words = words.strip('[')\n","        words = words.strip(']')\n","        words = words.split(',')\n","        words = [w.lstrip(' ') for w in words]\n","        words = [w.strip(\"'\") for w in words]\n","        words = [w for w in words if w != '']\n","\n","        return words\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45e2d0c97f7bdf8cbf3594beb6fdcda0.jpg</td>\n      <td>3</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>f74d1a5fc2498bbbfa045c74e3cc333e.jpg</td>\n      <td>3</td>\n      <td>[anti, club]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>f6c172096818c5fab10ecae722840798.jpg</td>\n      <td>3</td>\n      <td>[door, hello]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>251ffd610399ac00fea7709c642676ee.jpg</td>\n      <td>3</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>73c7328b8eda399199fdedec6e4badaf.jpg</td>\n      <td>3</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>105385</th>\n      <td>047a60001de0331608ba64092cc7ae2b.jpg</td>\n      <td>25</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105386</th>\n      <td>ea39ac66ccdc4b4d4c6443f6c54d8ae3.jpg</td>\n      <td>25</td>\n      <td>[dunia, fashion]</td>\n    </tr>\n    <tr>\n      <th>105387</th>\n      <td>6215f8c52c5bbcfe3e63e0f3ac6265f8.jpg</td>\n      <td>25</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105388</th>\n      <td>1733d8286f6658149c7b7cdeb40d6461.jpg</td>\n      <td>25</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>105389</th>\n      <td>8ee42460e9b6f3d909e32fdef2b6052f.jpg</td>\n      <td>25</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>105390 rows × 3 columns</p>\n</div>","text/plain":"                                    filename  category             words\n0       45e2d0c97f7bdf8cbf3594beb6fdcda0.jpg         3                []\n1       f74d1a5fc2498bbbfa045c74e3cc333e.jpg         3      [anti, club]\n2       f6c172096818c5fab10ecae722840798.jpg         3     [door, hello]\n3       251ffd610399ac00fea7709c642676ee.jpg         3                []\n4       73c7328b8eda399199fdedec6e4badaf.jpg         3                []\n...                                      ...       ...               ...\n105385  047a60001de0331608ba64092cc7ae2b.jpg        25                []\n105386  ea39ac66ccdc4b4d4c6443f6c54d8ae3.jpg        25  [dunia, fashion]\n105387  6215f8c52c5bbcfe3e63e0f3ac6265f8.jpg        25                []\n105388  1733d8286f6658149c7b7cdeb40d6461.jpg        25                []\n105389  8ee42460e9b6f3d909e32fdef2b6052f.jpg        25                []\n\n[105390 rows x 3 columns]"},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["df_train = pd.read_csv('./_csv_with_clean_text/train.min.csv')\n","df_train['words'] = df_train['words'].apply(to_list)\n","df_train\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fd663cf2b6e1d7b02938c6aaae0a32d2.jpg</td>\n      <td>43</td>\n      <td>[kafe, murah, kiss, meja]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>c7fd77508a8c355eaab0d4e10efd6b15.jpg</td>\n      <td>43</td>\n      <td>[come, pusat]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>127f3e6d6e3491b2459812353f33a913.jpg</td>\n      <td>43</td>\n      <td>[girl]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5ca4f2da11eda083064e6c36f37eeb81.jpg</td>\n      <td>43</td>\n      <td>[sniper, helmets, nails]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46d681a542f2c71be017eef6aae23313.jpg</td>\n      <td>43</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12181</th>\n      <td>5ba958eacb23cd7d1673bad4dae55784.jpg</td>\n      <td>43</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>12182</th>\n      <td>efbe41a1c2b666b70e337e438559808b.jpg</td>\n      <td>43</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>12183</th>\n      <td>79fdaa5ac5ba10dbe8004cabd8c35eb3.jpg</td>\n      <td>43</td>\n      <td>[happy, pumping]</td>\n    </tr>\n    <tr>\n      <th>12184</th>\n      <td>ac3d136124617637a05ba66694e381ef.jpg</td>\n      <td>43</td>\n      <td>[money, back, free, boas, balaga, single, pota...</td>\n    </tr>\n    <tr>\n      <th>12185</th>\n      <td>7ef61d7cfbad9cfe2db4f64560e3dddd.jpg</td>\n      <td>43</td>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>12186 rows × 3 columns</p>\n</div>","text/plain":"                                   filename  category  \\\n0      fd663cf2b6e1d7b02938c6aaae0a32d2.jpg        43   \n1      c7fd77508a8c355eaab0d4e10efd6b15.jpg        43   \n2      127f3e6d6e3491b2459812353f33a913.jpg        43   \n3      5ca4f2da11eda083064e6c36f37eeb81.jpg        43   \n4      46d681a542f2c71be017eef6aae23313.jpg        43   \n...                                     ...       ...   \n12181  5ba958eacb23cd7d1673bad4dae55784.jpg        43   \n12182  efbe41a1c2b666b70e337e438559808b.jpg        43   \n12183  79fdaa5ac5ba10dbe8004cabd8c35eb3.jpg        43   \n12184  ac3d136124617637a05ba66694e381ef.jpg        43   \n12185  7ef61d7cfbad9cfe2db4f64560e3dddd.jpg        43   \n\n                                                   words  \n0                              [kafe, murah, kiss, meja]  \n1                                          [come, pusat]  \n2                                                 [girl]  \n3                               [sniper, helmets, nails]  \n4                                                     []  \n...                                                  ...  \n12181                                                 []  \n12182                                                 []  \n12183                                   [happy, pumping]  \n12184  [money, back, free, boas, balaga, single, pota...  \n12185                                                 []  \n\n[12186 rows x 3 columns]"},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_test = pd.read_csv('./_csv_with_clean_text/test.min.csv')\n","df_test['words'] = df_test['words'].apply(to_list)\n","df_test\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["X_train = df_train['words'].copy()\n","X_train = X_train.apply(lambda words: ' '.join(words))\n","X_train = X_train.to_numpy()\n","\n","y_train = df_train['category'].copy()\n","y_train = y_train.to_numpy()\n","\n","X_test = df_test['words'].copy()\n","X_test = X_test.apply(lambda words: ' '.join(words))\n","X_test = X_test.to_numpy()\n","\n","y_test = df_test['category'].copy()\n","y_test = y_test.to_numpy()\n",""]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess word"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","bow_vectorizer = CountVectorizer(lowercase=False, binary=True)\n","tfidf_l1_vectorizer = TfidfVectorizer(lowercase=False, norm='l1', sublinear_tf=True)\n","tfidf_l2_vectorizer = TfidfVectorizer(lowercase=False, norm='l2', sublinear_tf=True)\n","\n","X_train_bow = bow_vectorizer.fit_transform(X_train)\n","X_train_tfidf_l1 = tfidf_l1_vectorizer.fit_transform(X_train)\n","X_train_tfidf_l2 = tfidf_l2_vectorizer.fit_transform(X_train)\n","\n","X_test_bow = bow_vectorizer.transform(X_test)\n","X_test_tfidf_l1 = tfidf_l1_vectorizer.transform(X_test)\n","X_test_tfidf_l2 = tfidf_l2_vectorizer.transform(X_test)\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["scipy.sparse.csr_matrix.sort_indices(X_train_bow)\n","scipy.sparse.csr_matrix.sort_indices(X_train_tfidf_l1)\n","scipy.sparse.csr_matrix.sort_indices(X_train_tfidf_l2)\n","\n","scipy.sparse.csr_matrix.sort_indices(X_test_bow)\n","scipy.sparse.csr_matrix.sort_indices(X_test_tfidf_l1)\n","scipy.sparse.csr_matrix.sort_indices(X_test_tfidf_l2)\n",""]},{"cell_type":"markdown","metadata":{},"source":["# Some functions"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization\n","\n","def test_model(model, X_test, y_test, filename):\n","    global df_test\n","    y_pred = model.predict(X_test)\n","    y_pred = np.argmax(y_pred, axis=-1)\n","\n","    # f1 = f1_score(y_test, y_pred, average='weighted')\n","    # print('Weighted F1 Score:', f1)\n","\n","    # print('Classification Report:')\n","    # print(classification_report(y_test, y_pred))\n","\n","    test_ids = df_test['filename'].to_numpy()\n","\n","    np.savetxt(filename, np.rec.fromarrays([test_ids, y_pred]), fmt=['%s', '%02d'], delimiter=',', header='filename,category', comments='')\n","\n","def compile_model(model):\n","    model.compile(\n","    optimizer=tfa.optimizers.RectifiedAdam(\n","        lr=0.005,\n","        total_steps=50,\n","        warmup_proportion=0.1,\n","        min_lr=0.001,\n","    ),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['sparse_categorical_accuracy'])\n","    return model\n",""]},{"cell_type":"markdown","metadata":{},"source":["# BOW + NN"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 42)                278628    \n=================================================================\nTotal params: 278,628\nTrainable params: 278,628\nNon-trainable params: 0\n_________________________________________________________________\n"}],"source":["model1 = Sequential([\n","    Input((6633, ), sparse=True),\n","    Dense(42, activation='softmax')\n","])\n","compile_model(model1)\n","model1.summary()\n",""]},{"cell_type":"code","execution_count":12,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 3.6450 - sparse_categorical_accuracy: 0.1910\nEpoch 2/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 3.3777 - sparse_categorical_accuracy: 0.2935\nEpoch 3/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 3.1610 - sparse_categorical_accuracy: 0.3110\nEpoch 4/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 3.0091 - sparse_categorical_accuracy: 0.3224\nEpoch 5/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.8996 - sparse_categorical_accuracy: 0.3293\nEpoch 6/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.8171 - sparse_categorical_accuracy: 0.3351\nEpoch 7/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.7528 - sparse_categorical_accuracy: 0.3390\nEpoch 8/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.7012 - sparse_categorical_accuracy: 0.3427\nEpoch 9/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.6590 - sparse_categorical_accuracy: 0.3456\nEpoch 10/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.6237 - sparse_categorical_accuracy: 0.3484\nEpoch 11/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.5939 - sparse_categorical_accuracy: 0.3509\nEpoch 12/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.5681 - sparse_categorical_accuracy: 0.3530\nEpoch 13/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.5459 - sparse_categorical_accuracy: 0.3551\nEpoch 14/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.5262 - sparse_categorical_accuracy: 0.3568\nEpoch 15/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.5087 - sparse_categorical_accuracy: 0.3584\nEpoch 16/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4931 - sparse_categorical_accuracy: 0.3598\nEpoch 17/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4790 - sparse_categorical_accuracy: 0.3613\nEpoch 18/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4661 - sparse_categorical_accuracy: 0.3623\nEpoch 19/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4545 - sparse_categorical_accuracy: 0.3636\nEpoch 20/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4437 - sparse_categorical_accuracy: 0.3647\nEpoch 21/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4338 - sparse_categorical_accuracy: 0.3659\nEpoch 22/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4247 - sparse_categorical_accuracy: 0.3669\nEpoch 23/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4162 - sparse_categorical_accuracy: 0.3676\nEpoch 24/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4083 - sparse_categorical_accuracy: 0.3688\nEpoch 25/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.4009 - sparse_categorical_accuracy: 0.3699\nEpoch 26/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3940 - sparse_categorical_accuracy: 0.3704\nEpoch 27/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3875 - sparse_categorical_accuracy: 0.3716\nEpoch 28/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3814 - sparse_categorical_accuracy: 0.3723\nEpoch 29/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3757 - sparse_categorical_accuracy: 0.3730\nEpoch 30/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3702 - sparse_categorical_accuracy: 0.3735\nEpoch 31/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3651 - sparse_categorical_accuracy: 0.3741\nEpoch 32/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3603 - sparse_categorical_accuracy: 0.3749\nEpoch 33/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3556 - sparse_categorical_accuracy: 0.3755\nEpoch 34/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3513 - sparse_categorical_accuracy: 0.3764\nEpoch 35/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3471 - sparse_categorical_accuracy: 0.3769\nEpoch 36/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3431 - sparse_categorical_accuracy: 0.3777\nEpoch 37/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3394 - sparse_categorical_accuracy: 0.3782\nEpoch 38/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3358 - sparse_categorical_accuracy: 0.3785\nEpoch 39/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3323 - sparse_categorical_accuracy: 0.3791\nEpoch 40/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3290 - sparse_categorical_accuracy: 0.3797\nEpoch 41/50\n1054/1054 [==============================] - 3s 3ms/step - loss: 2.3259 - sparse_categorical_accuracy: 0.3802\nEpoch 42/50\n1054/1054 [==============================] - 4s 3ms/step - loss: 2.3228 - sparse_categorical_accuracy: 0.3804\nEpoch 43/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3199 - sparse_categorical_accuracy: 0.3812\nEpoch 44/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3171 - sparse_categorical_accuracy: 0.3815\nEpoch 45/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3144 - sparse_categorical_accuracy: 0.3818\nEpoch 46/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3118 - sparse_categorical_accuracy: 0.3824\nEpoch 47/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3094 - sparse_categorical_accuracy: 0.3829\nEpoch 48/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3070 - sparse_categorical_accuracy: 0.3831\nEpoch 49/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3047 - sparse_categorical_accuracy: 0.3838\nEpoch 50/50\n1054/1054 [==============================] - 4s 4ms/step - loss: 2.3024 - sparse_categorical_accuracy: 0.3841\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe4779eb760>"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model1.fit(X_train_bow, y_train, batch_size=100, epochs=50, verbose=1)\n",""]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["test_model(model1, X_test_bow, y_test, 'model1.csv')\n",""]},{"cell_type":"markdown","metadata":{},"source":["# BOW + MLP"]},{"cell_type":"code","execution_count":14,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 331)               2195854   \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 331)               1324      \n_________________________________________________________________\nactivation (Activation)      (None, 331)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 110)               36520     \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 110)               440       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 110)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 42)                4662      \n=================================================================\nTotal params: 2,238,800\nTrainable params: 2,237,918\nNon-trainable params: 882\n_________________________________________________________________\n"}],"source":["model2 = Sequential([\n","    Input((6633, ), sparse=True),\n","\n","    Dense(331),\n","    BatchNormalization(),\n","    Activation('relu'),\n","\n","    Dense(110),\n","    BatchNormalization(),\n","    Activation('relu'),\n","\n","    Dense(42, activation='softmax')\n","])\n","compile_model(model2)\n","model2.summary()\n",""]},{"cell_type":"code","execution_count":15,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.9989 - sparse_categorical_accuracy: 0.2456\nEpoch 2/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.5665 - sparse_categorical_accuracy: 0.3337\nEpoch 3/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.4241 - sparse_categorical_accuracy: 0.3627\nEpoch 4/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.3520 - sparse_categorical_accuracy: 0.3777\nEpoch 5/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.3093 - sparse_categorical_accuracy: 0.3872\nEpoch 6/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.2779 - sparse_categorical_accuracy: 0.3944\nEpoch 7/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2573 - sparse_categorical_accuracy: 0.3993\nEpoch 8/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.2411 - sparse_categorical_accuracy: 0.4022\nEpoch 9/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2282 - sparse_categorical_accuracy: 0.4052\nEpoch 10/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.2166 - sparse_categorical_accuracy: 0.4069\nEpoch 11/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2091 - sparse_categorical_accuracy: 0.4092\nEpoch 12/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2029 - sparse_categorical_accuracy: 0.4089\nEpoch 13/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1973 - sparse_categorical_accuracy: 0.4098\nEpoch 14/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1912 - sparse_categorical_accuracy: 0.4108\nEpoch 15/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1868 - sparse_categorical_accuracy: 0.4113\nEpoch 16/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1827 - sparse_categorical_accuracy: 0.4118\nEpoch 17/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1778 - sparse_categorical_accuracy: 0.4129\nEpoch 18/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1759 - sparse_categorical_accuracy: 0.4136\nEpoch 19/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1726 - sparse_categorical_accuracy: 0.4128\nEpoch 20/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1685 - sparse_categorical_accuracy: 0.4134\nEpoch 21/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1673 - sparse_categorical_accuracy: 0.4135\nEpoch 22/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1654 - sparse_categorical_accuracy: 0.4133\nEpoch 23/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1628 - sparse_categorical_accuracy: 0.4140\nEpoch 24/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1604 - sparse_categorical_accuracy: 0.4145\nEpoch 25/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1589 - sparse_categorical_accuracy: 0.4153\nEpoch 26/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1564 - sparse_categorical_accuracy: 0.4149\nEpoch 27/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1559 - sparse_categorical_accuracy: 0.4154\nEpoch 28/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1537 - sparse_categorical_accuracy: 0.4158\nEpoch 29/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1516 - sparse_categorical_accuracy: 0.4154\nEpoch 30/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1506 - sparse_categorical_accuracy: 0.4160\nEpoch 31/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1500 - sparse_categorical_accuracy: 0.4153\nEpoch 32/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.1479 - sparse_categorical_accuracy: 0.4161\nEpoch 33/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1468 - sparse_categorical_accuracy: 0.4164\nEpoch 34/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1466 - sparse_categorical_accuracy: 0.4156\nEpoch 35/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1453 - sparse_categorical_accuracy: 0.4160\nEpoch 36/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1443 - sparse_categorical_accuracy: 0.4165\nEpoch 37/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1432 - sparse_categorical_accuracy: 0.4166\nEpoch 38/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1420 - sparse_categorical_accuracy: 0.4170\nEpoch 39/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1415 - sparse_categorical_accuracy: 0.4177\nEpoch 40/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1401 - sparse_categorical_accuracy: 0.4173\nEpoch 41/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1395 - sparse_categorical_accuracy: 0.4161\nEpoch 42/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1392 - sparse_categorical_accuracy: 0.4166\nEpoch 43/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1377 - sparse_categorical_accuracy: 0.4178\nEpoch 44/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1383 - sparse_categorical_accuracy: 0.4170\nEpoch 45/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1372 - sparse_categorical_accuracy: 0.4176\nEpoch 46/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1356 - sparse_categorical_accuracy: 0.4180\nEpoch 47/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1357 - sparse_categorical_accuracy: 0.4176\nEpoch 48/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1351 - sparse_categorical_accuracy: 0.4184\nEpoch 49/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1346 - sparse_categorical_accuracy: 0.4179\nEpoch 50/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1337 - sparse_categorical_accuracy: 0.4185\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe47c3b4100>"},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model2.fit(X_train_bow, y_train, batch_size=100, epochs=50, verbose=1)\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["test_model(model2, X_test_bow, y_test, 'model2.csv')"]},{"cell_type":"markdown","metadata":{},"source":["# TD-IDF + MLP"]},{"cell_type":"code","execution_count":17,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_4 (Dense)              (None, 331)               2195854   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 331)               1324      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 331)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 110)               36520     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 110)               440       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 110)               0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 42)                4662      \n=================================================================\nTotal params: 2,238,800\nTrainable params: 2,237,918\nNon-trainable params: 882\n_________________________________________________________________\n"}],"source":["model3 = Sequential([\n","    Input((6633, ), sparse=True),\n","\n","    Dense(331),\n","    BatchNormalization(),\n","    Activation('relu'),\n","\n","    Dense(110),\n","    BatchNormalization(),\n","    Activation('relu'),\n","\n","    Dense(42, activation='softmax')\n","])\n","compile_model(model3)\n","model3.summary()\n",""]},{"cell_type":"code","execution_count":18,"metadata":{"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.9904 - sparse_categorical_accuracy: 0.2483\nEpoch 2/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.5637 - sparse_categorical_accuracy: 0.3342\nEpoch 3/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.4325 - sparse_categorical_accuracy: 0.3602\nEpoch 4/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.3597 - sparse_categorical_accuracy: 0.3764\nEpoch 5/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.3139 - sparse_categorical_accuracy: 0.3864\nEpoch 6/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2816 - sparse_categorical_accuracy: 0.3940\nEpoch 7/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2571 - sparse_categorical_accuracy: 0.3988\nEpoch 8/50\n1054/1054 [==============================] - 12s 11ms/step - loss: 2.2404 - sparse_categorical_accuracy: 0.4028\nEpoch 9/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.2254 - sparse_categorical_accuracy: 0.4054\nEpoch 10/50\n1054/1054 [==============================] - 11s 10ms/step - loss: 2.2133 - sparse_categorical_accuracy: 0.4070\nEpoch 11/50\n1054/1054 [==============================] - 11s 10ms/step - loss: 2.2034 - sparse_categorical_accuracy: 0.4080\nEpoch 12/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1956 - sparse_categorical_accuracy: 0.4093\nEpoch 13/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1888 - sparse_categorical_accuracy: 0.4112\nEpoch 14/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1827 - sparse_categorical_accuracy: 0.4116\nEpoch 15/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1787 - sparse_categorical_accuracy: 0.4125\nEpoch 16/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1735 - sparse_categorical_accuracy: 0.4129\nEpoch 17/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1701 - sparse_categorical_accuracy: 0.4133\nEpoch 18/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1662 - sparse_categorical_accuracy: 0.4141\nEpoch 19/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1633 - sparse_categorical_accuracy: 0.4140\nEpoch 20/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1608 - sparse_categorical_accuracy: 0.4147\nEpoch 21/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1578 - sparse_categorical_accuracy: 0.4149\nEpoch 22/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1555 - sparse_categorical_accuracy: 0.4152\nEpoch 23/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1535 - sparse_categorical_accuracy: 0.4160\nEpoch 24/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1513 - sparse_categorical_accuracy: 0.4157\nEpoch 25/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1498 - sparse_categorical_accuracy: 0.4161\nEpoch 26/50\n1054/1054 [==============================] - 11s 10ms/step - loss: 2.1481 - sparse_categorical_accuracy: 0.4159\nEpoch 27/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1463 - sparse_categorical_accuracy: 0.4164\nEpoch 28/50\n1054/1054 [==============================] - 11s 10ms/step - loss: 2.1439 - sparse_categorical_accuracy: 0.4168\nEpoch 29/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1432 - sparse_categorical_accuracy: 0.4169\nEpoch 30/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1418 - sparse_categorical_accuracy: 0.4171\nEpoch 31/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1407 - sparse_categorical_accuracy: 0.4172\nEpoch 32/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1390 - sparse_categorical_accuracy: 0.4165\nEpoch 33/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1382 - sparse_categorical_accuracy: 0.4169\nEpoch 34/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1370 - sparse_categorical_accuracy: 0.4176\nEpoch 35/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1368 - sparse_categorical_accuracy: 0.4178\nEpoch 36/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1353 - sparse_categorical_accuracy: 0.4181\nEpoch 37/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1348 - sparse_categorical_accuracy: 0.4183\nEpoch 38/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1337 - sparse_categorical_accuracy: 0.4184\nEpoch 39/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1325 - sparse_categorical_accuracy: 0.4180\nEpoch 40/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1317 - sparse_categorical_accuracy: 0.4182\nEpoch 41/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1314 - sparse_categorical_accuracy: 0.4186\nEpoch 42/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1307 - sparse_categorical_accuracy: 0.4185\nEpoch 43/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1298 - sparse_categorical_accuracy: 0.4188\nEpoch 44/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1297 - sparse_categorical_accuracy: 0.4183\nEpoch 45/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1285 - sparse_categorical_accuracy: 0.4188\nEpoch 46/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1278 - sparse_categorical_accuracy: 0.4192\nEpoch 47/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1274 - sparse_categorical_accuracy: 0.4192\nEpoch 48/50\n1054/1054 [==============================] - 11s 10ms/step - loss: 2.1269 - sparse_categorical_accuracy: 0.4193\nEpoch 49/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1266 - sparse_categorical_accuracy: 0.4199\nEpoch 50/50\n1054/1054 [==============================] - 11s 11ms/step - loss: 2.1259 - sparse_categorical_accuracy: 0.4194\n"},{"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fe51c1c0c10>"},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model3.fit(X_train_tfidf_l2, y_train, batch_size=100, epochs=50, verbose=1)\n",""]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["test_model(model3, X_test_tfidf_l2, y_test, 'model3.csv')"]}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2},"nbformat":4,"nbformat_minor":2}